# Comparaison LiDAR 2015 et 2018

## Contexte
La classification des donn√©es LiDAR de 2015 et 2018 a √©t√© r√©alis√©e √† l'aide de deux algorithmes diff√©rents, entra√Ænant des disparit√©s dans les r√©sultats.

## Objectif
Comparer les donn√©es de plusieurs tuiles afin d‚Äôidentifier les diff√©rences dans la classification des nuages de points.

## Donn√©es
- **LiDAR 2015** : disponible sur le portail des donn√©es ouvertes de la Ville de Montr√©al.
- **LiDAR 2018** : donn√©es sur disque physique, transmises par la Ville de Montr√©al lors du contrat pour la mise √† jour de la carte de vuln√©rabilit√© face aux pluies abondantes de l'√©t√© 2024.

## M√©thodologie
1. S√©lection de 5 √† 6 tuiles LiDAR 2015 sur le portail des donn√©es ouvertes de la Ville de Montr√©al.

2. Conversion des fichiers **.LAZ** en **.LAS** :

- Sur *ArcGIS*, utiliser l'outil **Convertir des fichiers LAS** avec les param√®tres suivants :
	-  Aucune compression
	-  Toutes les options LAS d√©coch√©es
	-  Fichier LAS sans r√©f√©rence spatiale avec **EPSG : 32188** ou **EPSG : 2950** (4140 ne fonctionne pas).
 
3. Calculer des statistiques sur chaque tuile.

    - Sur ArcGIS avec **Statistiques d'un jeu de donn√©es LAS**

5. Comparer les statistiques entre 2015 et 2018 pour chaque tuiles


# 1er √âchantillon de test 

## Tuiles s√©lectionn√©es
- **299-5042** (sud-ouest du Parc La Fontaine)
- **297-5043** (ouest du parc Laurier)
- **297-5040** (Mont-Royal)
- **300-5046** (Parc Maisonneuve, stade olympique)
- **292-5048** (Parc-nature de l'√éle-de-la-Visitation)
- **284-5040** (Parc-nature du Bois-de-Liesse)


![alt text](image.png)


## Comparaison

### 299-5042
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 18.3 M         | 29.1 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 4.6 M          | 6.4 M          | 25.37 %          | 22.14 %          | <mark>-3.23 %        |
| V√©g√©tation haute  | 2.3 M          | 12.6 M         | 12.34 %          | 43.2 %           | <mark>+30.86 %       |
| B√¢timents         | 5.4 M          | 6.8 M          | 29.28 %          | 22.27 %          | -7.01 %              |

### 297-5043
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 21.1 M         | 24.2 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 6.9 M          | 7.6 M          | 32.93 %          | 31.22 %          | <mark> -1.71 %       |
| V√©g√©tation haute  | 1.3 M          | 6.0 M          | 5.92 %           | 24.71 %          | <mark> +18.79 %      |
| B√¢timents         | 5.7 M          | 6.3 M          | 27.07 %          | 25.92 %          | -1.15 %              |

### 297-5040
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 29.2 M         | 26.0 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 1.4 M          | 8.2 M          | 8.47 %           | 31.57 %          | <mark>+23.1 %        |
| V√©g√©tation haute  | 1.9 M          | 8.9 M          | 11.51 %          | 34.46 %          | <mark>+22.95 %       |
| B√¢timents         | 2.9 M          | 3.9 M          | 17.8 %           | 14.88 %          | -2.92 %              |

### 300-5046
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 21.1 M         | 24.2 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 6.9 M          | 7.6 M          | 32.93 %          | 31.22 %          | <mark>-1.71 %        |
| V√©g√©tation haute  | 1.3 M          | 6.0 M          | 5.92 %           | 24.71 %          | <mark>+18.79 %       |
| B√¢timents         | 5.7 M          | 6.3 M          | 27.07 %          | 25.92 %          | -1.15 %              |

### 292-5048
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 16.0 M         | 27.8 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 4.5 M          | 6.0 M          | 28.04 %          | 21.66 %          | <mark>-6.38 %        |
| V√©g√©tation haute  | 3.0 M          | 14.6 M         | 18.88 %          | 52.69 %          | <mark>+33.81 %       |
| B√¢timents         | 2.3 M          | 3.0 M          | 14.02 %          | 10.81 %          | -3.21 %              |

### 284-5040
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | Diff√©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 17.0 M         | 31.7 M         | 100 %            | 100 %            | x                    |
| Non classifi√©     | 6.5 M          | 7.5 M          | 38.27 %          | 23.53 %          | <mark>-14.74 %       |
| V√©g√©tation haute  | 1.8 M          | 16.7 M         | 10.41 %          | 52.75 %          | <mark>+42.34 %       |
| B√¢timents         | 1.1 M          | 1.4 M          | 6.31 %           | 4.47 %           | -1.84 %              |


## Conclusion

Sur cet √©chantillon, on observe une baisse globale du pourcentage de donn√©es non classifi√©es entre 2015 et 2018, √† l'exception d‚Äôune seule tuile. Cette derni√®re correspond √† une partie du Mont-Royal.
En revanche, le nombre de points classifi√©s en **"V√©g√©tation haute"** augmente significativement entre les deux ann√©es, avec une hausse moyenne de 27 % entre 2015 et 2018.

### Pistes expliquant ces diff√©rences

La forte augmentation du pourcentage de points classifi√©s en **"V√©g√©tation haute"** entre 2015 et 2018 peut s'expliquer par plusieurs facteurs. Le portail des donn√©es ouvertes de la Ville de Montr√©al indique que les donn√©es **LiDAR 2015** ont √©t√© mises √† jour en **novembre 2015**. Cependant, il n‚Äôest pas pr√©cis√© si cette mise √† jour correspond √† la date de production ou simplement √† la date de traitement des donn√©es.

Si la donn√©e a effectivement √©t√© acquise en novembre 2015, une p√©riode o√π la v√©g√©tation est r√©duite, cela pourrait expliquer cette diff√©rence dans la classification.

Pour valider cette hypoth√®se, il serait n√©cessaire d‚Äôobtenir les dates exactes de production des donn√©es LiDAR **2015** et **2018**.


## √Ä faire pour le LiDAR

L‚Äô√©chantillon s√©lectionn√© √©tant trop restreint, il ne permet pas de tirer des conclusions d√©finitives sur les diff√©rences de classification entre 2015 et 2018.

‚û° **Trouver une solution pour r√©aliser ce r√©sum√© statistique sur l‚Äôensemble des tuiles.**

Pour chaque tuile :
  - Calculer les statistiques de **2015** et **2018**
  - Calculer le poucentage de points **"non classifi√©s"**
  - Faire la diff√©rence de 2018 sur 2015
  - Relever le num√©ro des tuiles dont ce pourcentage est sup√©rieur √† **30%**
 
## üìö Recherches effectu√©es sur le traitement des donn√©es LiDAR en Python  

Utilisation de la biblioth√®que **laspy** :  
- üìå [Documentation principale](https://laspy.readthedocs.io/en/latest/)  
- üìå [Guide d'installation](https://laspy.readthedocs.io/en/latest/installation.html)  


‚û° Question pos√©e √† Rodolphe pour la m√©thodologie du code.

## R√©ponse de Rodolphe

	resulats2015 = []
		for t2015 in tuiles2015:
		resultats2015.append(calculsStats(t2015))

# Semaine du 03 mars: 

## Reprise du Code pour le Calcul Automatique des Diff√©rences de Classification  

![image](https://github.com/user-attachments/assets/68b66866-8bb6-466e-96ed-108882314d6d)  

### üöÄ Progr√®s et ajustements  

Pour effectuer les calculs sur toutes les tuiles, j‚Äôai envisag√© de cr√©er un Google Drive afin d‚Äôy stocker toutes les tuiles LiDAR. Les fichiers √©tant trop volumineux, cette solution s‚Äôest av√©r√©e inadapt√©e.  

#### üîß Solution adopt√©e  
‚úÖ Installation d'**Anaconda** pour travailler sous **Jupyter Notebook**.  
‚úÖ Ajout des **149 premi√®res tuiles** (de **296** √† **279**).  
‚è≥ **Prochaine √©tape** : Reprendre √† **280** pour compl√©ter l‚Äôensemble des donn√©es.  

#### üíª D√©veloppement du Code  
üîπ Finalement, le code a √©t√© repris et ex√©cut√© sous **Spyder**.  
üîπ Cr√©ation d‚Äôun script permettant de **calculer automatiquement le pourcentage de points classifi√©s** selon une classification donn√©e **"x"**.  
üîπ Les r√©sultats sont int√©gr√©s dans un **DataFrame**, comprenant :  
   - Une **colonne indiquant le nom de la tuile** trait√©e.  
   - Une **colonne contenant le r√©sultat du calcul**.  
Reprise du Code pour le calcul automatique de la diff√©rence du pourcentage de point selon leur classification


### 1er Prototype fonctionnel

	resultats2018 = []
	tuiles2018 = []

	def pourcentage2018(dossier):

    		for f in os.listdir(dossier):
        
        		if f.endswith('.las'):
            
            			chemin_fichier = os.path.join(dossier, f)
            
            
            		with lp.open(chemin_fichier) as g:
                
                		t2018 = g.read()
               
                		num_points = len(t2018)
                
                
                		num_points_classcode = len(t2018[t2018.classification == 5])
               
                		pourcentage_points_classecode = (num_points_classcode/num_points) *100
                
                		numero_tuile = f[:8]
               
                		resultats2018.append(pourcentage_points_classecode)
                
                		tuiles2018.append(numero_tuile)
                
                
                
    	return resultats2018, tuiles2018

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR\TEST"
	resultats =  pourcentage2018(dossier)

	for pourcentage_points_classecode in resultats2018:
    		print(f"{pourcentage_points_classecode}% de points non classifi√©s")
	for numero_tuile in tuiles2018:
    		print(f"Tuile {numero_tuile}")

![image](https://github.com/user-attachments/assets/b9dde783-7bf5-4188-90fe-aa4898c9d4ce)

# Semaine du 10 mars :
### 2√®me prototype fonctionnel

Avanc√© du code, Code termin√© avec un code pour calculer les pourcentage des points classifi√©s en "x" code de classe pour les tuiles 2018 :



	import lazrs
	import pandas as pd
	import laspy as lp
	import os


	# Calcul du pourcentage de points classifi√©s en "x" code de classe pour l'ann√©e 2018:
    
	resultats2018 = [] # Liste vide contenant les r√©ultats du calcule du pourcentage de points classifi√© selon "x" classecode

	tuiles2018 = [] # Liste vide contenant le nom de la tuile qui est calcul√©

	def pourcentage2018(dossier): # Fonction qui calcule
    
    		for f in os.listdir(dossier):
            
        		if f.endswith('.las'): # S'assurer que seuls les fichier .las sont s√©lectionn√©s
                
            		chemin_fichier = os.path.join(dossier, f)
                
            			with lp.open(chemin_fichier) as g: # Ouvrir le 
                    
               			t2018 = g.read()
                   
                		num_points = len(t2018) # Nombre de points dans la tuile
                
                		if num_points > 0: # Filtre pour ne pas diviser par 0 mais sc√©nario impossible ici.
                    
                    			num_points_classcode = len(t2018[t2018.classification == 1]) # Nombre de points classifi√© selon le code de classe choisi
                   
                    			pourcentage_points_classecode = (num_points_classcode/num_points) *100 # Calcule du pourcentage
                    
                		else:
                    			pourcentage_points_classecode = 0.0
                
                		numero_tuile = f[:8] # Chercher le nom de la tuile (les 9 premiers caract√®res du fichier)
                   
                		resultats2018.append(pourcentage_points_classecode) # Ajouter le pourcentage √† la liste resultats2018
                    
                		tuiles2018.append(numero_tuile) # Ajouter le nom de la tuile √† la liste tuiles2018
                
    		df_resultats2018 = pd.DataFrame(
        	{'Tuile2018': tuiles2018,
         	'Pourcentage de points classifi√©s 2018 (Classe 1)': resultats2018
    		}) # Mettre le r√©sultat des deux listes dans un dataframe
                    
                    
                    
    		return df_resultats2018

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR_2018\LAS_classifiees\266-279"
	df_resultats_2018 =  pourcentage2018(dossier)


Un second pour les tuiles 2015 : 

	# Calcul du pourcentage de points classifi√© en "x" code de classe pour l'ann√©e 2015:
    
	resultats2015 = [] # Liste vide contenant les r√©ultats du calcule du pourcentage de points classifi√© selon "x" classecode

	tuiles2015 = [] # Liste vide contenant le nom de la tuile qui est calcul√©

	def pourcentage2015(dossier): # Fonction qui calcule
    
   		for f in os.listdir(dossier):
            
        		if f.endswith('.las'): # S'assurer que seuls les fichier .las sont s√©lectionn√©s
                
            			chemin_fichier = os.path.join(dossier, f)
                
            			with lp.open(chemin_fichier) as g: # Ouvrir le 
                    
                		t2015 = g.read()
                   
                		num_points = len(t2015) # Nombre de points dans la tuile
                
                		if num_points > 0: # Filtre pour ne pas diviser par 0 mais sc√©nario impossible ici.
                    
                    			num_points_classcode = len(t2015[t2015.classification == 1]) # Nombre de points classifi√© selon le code de classe choisi
                   
                    			pourcentage_points_classecode = (num_points_classcode/num_points) *100 # Calcule du pourcentage
                    
                		else:
                    			pourcentage_points_classecode = 0.0
                
                		numero_tuile = f[:8] # Chercher le nom de la tuile (les 9 premiers caract√®res du fichier)
                   
                		resultats2015.append(pourcentage_points_classecode) # Ajouter le pourcentage √† la liste resultats2018
                    
                		tuiles2015.append(numero_tuile) # Ajouter le nom de la tuile √† la liste tuiles2018
                
    		df_resultats2015 = pd.DataFrame(
        	{'Tuile2015': tuiles2015,
         	'Pourcentage de points classifi√©s 2015 (Classe 1)': resultats2015
    		}) # Mettre le r√©sultat des deux listes dans un dataframe
                    
                    
                    
    		return df_resultats2015

	dossier = r"D:\UNIVERSITE\UQAM\Contrat\Comparaison_2015_2018\LiDAR_2015\LAS2015_classifiees_266-279"
	df_resultats_2015 =  pourcentage2015(dossier)


# 2√®me √©chantillon de test.

## üõ†Ô∏è Test du Code sur un √âchantillon R√©duit  

Pour tester ce code, j‚Äôai effectu√© un test sur un **√©chantillon r√©duit** comprenant **5 tuiles** de 2015 et **5 tuiles** de 2018.  

### üéØ Objectif du Test  
L‚Äôobjectif √©tait simplement de **v√©rifier le bon fonctionnement du code**, sans chercher √† comparer directement les valeurs entre 2015 et 2018.  

### ‚ö†Ô∏è Diff√©rences dans l‚Äô√©chantillon  
üö® **Les tuiles s√©lectionn√©es ne sont pas les m√™mes pour 2015 et 2018**, car je n'avais pas pr√©vu de soustraire les r√©sultats entre les deux ann√©es.  
üîç Le test visait uniquement √† s‚Äôassurer que les **r√©sultats √©taient coh√©rents** :  
- **Le calcul du pourcentage √©tait correct**.  
- **Chaque tuile √©tait bien associ√©e √† son r√©sultat dans le DataFrame*


# 3√®me √©chantillon de test

## üîÑ Fusion des DataFrames pour l'Analyse des Diff√©rences  

Les codes pour le calcul des pourcentages √©tant **fonctionnels**, j‚Äôai ajout√© une **section fusionnant les deux DataFrames** en un seul.  

### üéØ Objectif  
L‚Äôobjectif est de **regrouper toutes les donn√©es** dans un **unique DataFrame** afin de faciliter l‚Äôanalyse des diff√©rences entre 2015 et 2018.  

### üîß M√©thode  

**Fusion des DataFrames** avec la m√©thode **.merge**



	# Fusion des 2 DataFrame et soustraction des r√©sultats

	df_comparaison = df_resultats_2018.merge(df_resultats_2015[["Tuile2015", "Pourcentage de points classifi√©s 2015 (Classe 1)" ]], left_on="Tuile2018", right_on="Tuile2015", how="left")
	df_comparaison["Diff√©rence"] = df_comparaison["Pourcentage de points classifi√©s 2018 (Classe 1)"] - df_comparaison["Pourcentage de points classifi√©s 2015 (Classe 1)"]

	print(df_comparaison)
 

### üß™ Test de Fusion avec Donn√©es Non Concordantes  

Apres quoi j'ai r√©alis√© le premier test complet, sur un √©chantillon r√©duit : 


| Tuile      | 2015     | 2018     |
|------------|---------|---------|
| 295-5029   | ‚úÖ       | ‚ùå       |
| 295-5030   | ‚úÖ       | ‚úÖ       |
| 295-5031   | ‚úÖ       | ‚úÖ       |
| 295-5032   | ‚úÖ       | ‚úÖ       |
| 295-5033   | ‚úÖ       | ‚úÖ       |
| 295-5034   | ‚ùå       | ‚úÖ       |



J‚Äôai **d√©lib√©r√©ment choisi** des donn√©es **non parfaitement concordantes** entre **2015 et 2018** afin d‚Äôobserver le comportement du code lors de la fusion des deux DataFrames.  

### üéØ Objectif  
Tester la gestion des **valeurs manquantes** et v√©rifier si la fusion des DataFrames entra√Æne des erreurs ou un d√©calage des lignes.  

### ‚úÖ R√©sultats  
- **R√©sultat positif** :  
  - Lorsque le code ne peut pas effectuer la soustraction entre 2018 et 2015 (car une tuile est absente d‚Äôun des jeux de donn√©es), le **DataFrame ins√®re un "NaN"**.  
  - **Aucun d√©calage** observ√© dans les lignes du DataFrame.  

üîç **Conclusion** : Le code g√®re correctement les donn√©es non concordantes et maintient l‚Äôint√©grit√© des r√©sultats.  


# 4√®me √©chantillon

## üìä Test de Grande Ampleur sur le premier fichiers de tuiles (266-279)  

### üöÄ R√©sultats du Test  
- **Succ√®s pour 2015** ‚úÖ  
- **√âchec pour 2018** ‚ùå : Un fichier semble √™tre corrompu.  

### üîç D√©tection du Fichier Corrompu  
Pour identifier le fichier probl√©matique, j‚Äôai ex√©cut√© le code suivant :

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR_2018\LAS_classifiees\266-279"

	for f in os.listdir(dossier):
    		if f.endswith('.las'):
        	chemin_fichier = os.path.join(dossier, f)
       		 with open(chemin_fichier, "rb") as fichier:
            		signature = fichier.read(4)
        	print(f"{f} ‚Üí Signature : {signature}")

Le script permet de relever la **signature des fichiers**.  
üîπ Un fichier `.LAS` doit avoir une **signature = `b'LASF'`**.  
üîπ Une tuile **(279-5031)** √©tait corrompue.  
üöÄ **Action** : Je l‚Äôai retir√©e du dossier avant de relancer le code.  

‚úÖ **Succ√®s** : Le script fonctionne correctement apr√®s cette correction.  

---

## üìÇ Export des R√©sultats et Visualisation  

Le code suivant permet de **transposer les r√©sultats dans un fichier CSV**.  
üìå **Proc√©dure** :  
1. Ouverture du fichier dans **Excel**.  
2. R√©enregistrement au format **CSV**.  
3. Import dans **ArcGIS**.
4. **Jointure avec le fichier shapefile des tuiles LiDAR 2015** pour visualiser les r√©sultats.  

![image](https://github.com/user-attachments/assets/9f175a29-fffb-4374-b055-a16a2489d0a3)

üîé **Observation** :  
‚û°Ô∏è **Augmentation du pourcentage de points non classifi√©s** pour **les tuiles de l‚Äôextr√™me est de l‚Äô√Æle**.  

---

## üìÖ Semaine du 17 mars  

### üìå Analyse des donn√©es "non-classifi√©es" (2015 vs 2018)  

üîπ Ex√©cution du script pour **toutes les tuiles** classifi√©es en **"non-classifi√©es"** en 2015 et 2018.  
üîπ Fusion des **5 CSV par ann√©e (2015 et 2018)** dans **ArcGIS** (`Comparaison_LiDAR_Classe1`).  
üîπ **Jointure** entre le fichier fusionn√© et la couche **shapefile des tuiles LiDAR**.  

### üìä R√©sultats de l'analyse  

![image](https://github.com/user-attachments/assets/1ba3e2fd-4767-4def-af80-c4937dd12f0b)

üî∏ **L√©gende** :  
‚úîÔ∏è **Vert fonc√©** ‚Üí Forte diminution du pourcentage de points "non-classifi√©s" entre 2015 et 2018.  
‚ö†Ô∏è **Orange / Rouge** ‚Üí Augmentation de plus de **15% √† 30%** du pourcentage de points "non-classifi√©s" entre 2018 et 2015.  

üìå **Tendance g√©n√©rale** :  
‚û°Ô∏è **60% des tuiles** ont un **taux plus √©lev√© de points "non-classifi√©s" en 2018** qu'en 2015.  

---

### üåø Analyse des donn√©es "V√©g√©tation haute" (2015 vs 2018)  

üîπ **M√™me script**, seule la classification change :  

	num_points_classcode = len(t2015[t2015.classification == 5])  # Nombre de points classifi√©s selon le code choisi


üìå **Proc√©dure identique** :  
1. Ouverture du fichier dans **Excel**.  
2. R√©enregistrement au format **CSV**.  
3. Import dans **ArcGIS**.
4. **Jointure avec le fichier shapefile des tuiles LiDAR 2015** pour visualiser les r√©sultats.

![image](https://github.com/user-attachments/assets/ca46a135-a92c-4225-b6b6-ea6b7f46a9bd)

üîé**Observation √©tonnante** :
‚û°Ô∏è Pour une grande majorit√© de l'√Æle, le nombre de points classifi√©s en "v√©g√©tation haute" a augment√© d‚Äôau moins 10% entre 2015 et 2018. Ce r√©sultat vient contredire ceux obtenus lors de notre premier √©chantillon test.

# üìå R√©sum√© des r√©sultats

- **60% des tuiles** ont un pourcentage plus √©lev√© de points **"non-classifi√©s" en 2018** qu'en 2015.
- **9.7% des tuiles** montrent une augmentation du pourcentage de points classifi√©s en **"v√©g√©tation haute" en 2018** par rapport √† 2015.


# Suite du travail

- Effectuer le code pour les points classifi√©s en **"V√©g√©tation-moyenne"** et **"v√©g√©tation-basse"**
- Trouver une m√©thode pour assigner une classification aux valeurs non-classifi√©es dans les tuiles ou leur poucentage d√©passe une valeur seuil **"x"**
