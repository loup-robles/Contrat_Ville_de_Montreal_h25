# Comparaison LiDAR 2015 et 2018

## Contexte
La classification des donnÃ©es LiDAR de 2015 et 2018 a Ã©tÃ© rÃ©alisÃ©e Ã  l'aide de deux algorithmes diffÃ©rents, entraÃ®nant des disparitÃ©s dans les rÃ©sultats.

## Objectif
Comparer les donnÃ©es de plusieurs tuiles afin dâ€™identifier les diffÃ©rences dans la classification des nuages de points.

## DonnÃ©es
- **LiDAR 2015** : disponible sur le portail des donnÃ©es ouvertes de la Ville de MontrÃ©al.
- **LiDAR 2018** : donnÃ©es sur disque physique, transmises par la Ville de MontrÃ©al lors du contrat pour la mise Ã  jour de la carte de vulnÃ©rabilitÃ© face aux pluies abondantes de l'Ã©tÃ© 2024.

## MÃ©thodologie
1. SÃ©lection de 5 Ã  6 tuiles LiDAR 2015 sur le portail des donnÃ©es ouvertes de la Ville de MontrÃ©al.

2. Conversion des fichiers **.LAZ** en **.LAS** :

- Sur *ArcGIS*, utiliser l'outil **Convertir des fichiers LAS** avec les paramÃ¨tres suivants :
	-  Aucune compression
	-  Toutes les options LAS dÃ©cochÃ©es
	-  Fichier LAS sans rÃ©fÃ©rence spatiale avec **EPSG : 32188** ou **EPSG : 2950** (4140 ne fonctionne pas).
 
3. Calculer des statistiques sur chaque tuile.

    - Sur ArcGIS avec **Statistiques d'un jeu de donnÃ©es LAS**

5. Comparer les statistiques entre 2015 et 2018 pour chaque tuiles


# 1er Ã‰chantillon de test 

## Tuiles sÃ©lectionnÃ©es
- **299-5042** (sud-ouest du Parc La Fontaine)
- **297-5043** (ouest du parc Laurier)
- **297-5040** (Mont-Royal)
- **300-5046** (Parc Maisonneuve, stade olympique)
- **292-5048** (Parc-nature de l'Ãle-de-la-Visitation)
- **284-5040** (Parc-nature du Bois-de-Liesse)


![alt text](image.png)


## Comparaison

### 299-5042
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 18.3 M         | 29.1 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 4.6 M          | 6.4 M          | 25.37 %          | 22.14 %          | <mark>-3.23 %        |
| VÃ©gÃ©tation haute  | 2.3 M          | 12.6 M         | 12.34 %          | 43.2 %           | <mark>+30.86 %       |
| BÃ¢timents         | 5.4 M          | 6.8 M          | 29.28 %          | 22.27 %          | -7.01 %              |

### 297-5043
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 21.1 M         | 24.2 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 6.9 M          | 7.6 M          | 32.93 %          | 31.22 %          | <mark> -1.71 %       |
| VÃ©gÃ©tation haute  | 1.3 M          | 6.0 M          | 5.92 %           | 24.71 %          | <mark> +18.79 %      |
| BÃ¢timents         | 5.7 M          | 6.3 M          | 27.07 %          | 25.92 %          | -1.15 %              |

### 297-5040
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 29.2 M         | 26.0 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 1.4 M          | 8.2 M          | 8.47 %           | 31.57 %          | <mark>+23.1 %        |
| VÃ©gÃ©tation haute  | 1.9 M          | 8.9 M          | 11.51 %          | 34.46 %          | <mark>+22.95 %       |
| BÃ¢timents         | 2.9 M          | 3.9 M          | 17.8 %           | 14.88 %          | -2.92 %              |

### 300-5046
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 21.1 M         | 24.2 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 6.9 M          | 7.6 M          | 32.93 %          | 31.22 %          | <mark>-1.71 %        |
| VÃ©gÃ©tation haute  | 1.3 M          | 6.0 M          | 5.92 %           | 24.71 %          | <mark>+18.79 %       |
| BÃ¢timents         | 5.7 M          | 6.3 M          | 27.07 %          | 25.92 %          | -1.15 %              |

### 292-5048
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 16.0 M         | 27.8 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 4.5 M          | 6.0 M          | 28.04 %          | 21.66 %          | <mark>-6.38 %        |
| VÃ©gÃ©tation haute  | 3.0 M          | 14.6 M         | 18.88 %          | 52.69 %          | <mark>+33.81 %       |
| BÃ¢timents         | 2.3 M          | 3.0 M          | 14.02 %          | 10.81 %          | -3.21 %              |

### 284-5040
| Classification     | Nb points 2015 | Nb points 2018 | Pourcentage 2015 | Pourcentage 2018 | DiffÃ©rence 2018-2015 |
|-------------------|----------------|----------------|------------------|------------------|----------------------|
| Tous              | 17.0 M         | 31.7 M         | 100 %            | 100 %            | x                    |
| Non classifiÃ©     | 6.5 M          | 7.5 M          | 38.27 %          | 23.53 %          | <mark>-14.74 %       |
| VÃ©gÃ©tation haute  | 1.8 M          | 16.7 M         | 10.41 %          | 52.75 %          | <mark>+42.34 %       |
| BÃ¢timents         | 1.1 M          | 1.4 M          | 6.31 %           | 4.47 %           | -1.84 %              |


## Conclusion

Sur cet Ã©chantillon, on observe une baisse globale du pourcentage de donnÃ©es non classifiÃ©es entre 2015 et 2018, Ã  l'exception dâ€™une seule tuile. Cette derniÃ¨re correspond Ã  une partie du Mont-Royal.
En revanche, le nombre de points classifiÃ©s en **"VÃ©gÃ©tation haute"** augmente significativement entre les deux annÃ©es, avec une hausse moyenne de 27 % entre 2015 et 2018.

### Pistes expliquant ces diffÃ©rences

La forte augmentation du pourcentage de points classifiÃ©s en **"VÃ©gÃ©tation haute"** entre 2015 et 2018 peut s'expliquer par plusieurs facteurs. Le portail des donnÃ©es ouvertes de la Ville de MontrÃ©al indique que les donnÃ©es **LiDAR 2015** ont Ã©tÃ© mises Ã  jour en **novembre 2015**. Cependant, il nâ€™est pas prÃ©cisÃ© si cette mise Ã  jour correspond Ã  la date de production ou simplement Ã  la date de traitement des donnÃ©es.

Si la donnÃ©e a effectivement Ã©tÃ© acquise en novembre 2015, une pÃ©riode oÃ¹ la vÃ©gÃ©tation est rÃ©duite, cela pourrait expliquer cette diffÃ©rence dans la classification.

Pour valider cette hypothÃ¨se, il serait nÃ©cessaire dâ€™obtenir les dates exactes de production des donnÃ©es LiDAR **2015** et **2018**.


## Ã€ faire pour le LiDAR

Lâ€™Ã©chantillon sÃ©lectionnÃ© Ã©tant trop restreint, il ne permet pas de tirer des conclusions dÃ©finitives sur les diffÃ©rences de classification entre 2015 et 2018.

â¡ **Trouver une solution pour rÃ©aliser ce rÃ©sumÃ© statistique sur lâ€™ensemble des tuiles.**

Pour chaque tuile :
  - Calculer les statistiques de **2015** et **2018**
  - Calculer le poucentage de points **"non classifiÃ©s"**
  - Faire la diffÃ©rence de 2018 sur 2015
  - Relever le numÃ©ro des tuiles dont ce pourcentage est supÃ©rieur Ã  **30%**
 
## ğŸ“š Recherches effectuÃ©es sur le traitement des donnÃ©es LiDAR en Python  

Utilisation de la bibliothÃ¨que **laspy** :  
- ğŸ“Œ [Documentation principale](https://laspy.readthedocs.io/en/latest/)  
- ğŸ“Œ [Guide d'installation](https://laspy.readthedocs.io/en/latest/installation.html)  


â¡ Question posÃ©e Ã  Rodolphe pour la mÃ©thodologie du code.

## RÃ©ponse de Rodolphe

	resulats2015 = []
		for t2015 in tuiles2015:
		resultats2015.append(calculsStats(t2015))

# Semaine du 03 mars: 

## Reprise du Code pour le Calcul Automatique des DiffÃ©rences de Classification  

![image](https://github.com/user-attachments/assets/68b66866-8bb6-466e-96ed-108882314d6d)  

### ğŸš€ ProgrÃ¨s et ajustements  

Pour effectuer les calculs sur toutes les tuiles, jâ€™ai envisagÃ© de crÃ©er un Google Drive afin dâ€™y stocker toutes les tuiles LiDAR. Les fichiers Ã©tant trop volumineux, cette solution sâ€™est avÃ©rÃ©e inadaptÃ©e.  

#### ğŸ”§ Solution adoptÃ©e  
âœ… Installation d'**Anaconda** pour travailler sous **Jupyter Notebook**.  
âœ… Ajout des **149 premiÃ¨res tuiles** (de **296** Ã  **279**).  
â³ **Prochaine Ã©tape** : Reprendre Ã  **280** pour complÃ©ter lâ€™ensemble des donnÃ©es.  

#### ğŸ’» DÃ©veloppement du Code  
ğŸ”¹ Finalement, le code a Ã©tÃ© repris et exÃ©cutÃ© sous **Spyder**.  
ğŸ”¹ CrÃ©ation dâ€™un script permettant de **calculer automatiquement le pourcentage de points classifiÃ©s** selon une classification donnÃ©e **"x"**.  
ğŸ”¹ Les rÃ©sultats sont intÃ©grÃ©s dans un **DataFrame**, comprenant :  
   - Une **colonne indiquant le nom de la tuile** traitÃ©e.  
   - Une **colonne contenant le rÃ©sultat du calcul**.  
Reprise du Code pour le calcul automatique de la diffÃ©rence du pourcentage de point selon leur classification


### 1er Prototype fonctionnel

	resultats2018 = []
	tuiles2018 = []

	def pourcentage2018(dossier):

    		for f in os.listdir(dossier):
        
        		if f.endswith('.las'):
            
            			chemin_fichier = os.path.join(dossier, f)
            
            
            		with lp.open(chemin_fichier) as g:
                
                		t2018 = g.read()
               
                		num_points = len(t2018)
                
                
                		num_points_classcode = len(t2018[t2018.classification == 5])
               
                		pourcentage_points_classecode = (num_points_classcode/num_points) *100
                
                		numero_tuile = f[:8]
               
                		resultats2018.append(pourcentage_points_classecode)
                
                		tuiles2018.append(numero_tuile)
                
                
                
    	return resultats2018, tuiles2018

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR\TEST"
	resultats =  pourcentage2018(dossier)

	for pourcentage_points_classecode in resultats2018:
    		print(f"{pourcentage_points_classecode}% de points non classifiÃ©s")
	for numero_tuile in tuiles2018:
    		print(f"Tuile {numero_tuile}")

![image](https://github.com/user-attachments/assets/b9dde783-7bf5-4188-90fe-aa4898c9d4ce)

# Semaine du 10 mars :
### 2Ã¨me prototype fonctionnel

AvancÃ© du code, Code terminÃ© avec un code pour calculer les pourcentage des points classifiÃ©s en "x" code de classe pour les tuiles 2018 :



	import lazrs
	import pandas as pd
	import laspy as lp
	import os


	# Calcul du pourcentage de points classifiÃ©s en "x" code de classe pour l'annÃ©e 2018:
    
	resultats2018 = [] # Liste vide contenant les rÃ©ultats du calcule du pourcentage de points classifiÃ© selon "x" classecode

	tuiles2018 = [] # Liste vide contenant le nom de la tuile qui est calculÃ©

	def pourcentage2018(dossier): # Fonction qui calcule
    
    		for f in os.listdir(dossier):
            
        		if f.endswith('.las'): # S'assurer que seuls les fichier .las sont sÃ©lectionnÃ©s
                
            		chemin_fichier = os.path.join(dossier, f)
                
            			with lp.open(chemin_fichier) as g: # Ouvrir le 
                    
               			t2018 = g.read()
                   
                		num_points = len(t2018) # Nombre de points dans la tuile
                
                		if num_points > 0: # Filtre pour ne pas diviser par 0 mais scÃ©nario impossible ici.
                    
                    			num_points_classcode = len(t2018[t2018.classification == 1]) # Nombre de points classifiÃ© selon le code de classe choisi
                   
                    			pourcentage_points_classecode = (num_points_classcode/num_points) *100 # Calcule du pourcentage
                    
                		else:
                    			pourcentage_points_classecode = 0.0
                
                		numero_tuile = f[:8] # Chercher le nom de la tuile (les 9 premiers caractÃ¨res du fichier)
                   
                		resultats2018.append(pourcentage_points_classecode) # Ajouter le pourcentage Ã  la liste resultats2018
                    
                		tuiles2018.append(numero_tuile) # Ajouter le nom de la tuile Ã  la liste tuiles2018
                
    		df_resultats2018 = pd.DataFrame(
        	{'Tuile2018': tuiles2018,
         	'Pourcentage de points classifiÃ©s 2018 (Classe 1)': resultats2018
    		}) # Mettre le rÃ©sultat des deux listes dans un dataframe
                    
                    
                    
    		return df_resultats2018

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR_2018\LAS_classifiees\266-279"
	df_resultats_2018 =  pourcentage2018(dossier)


Un second pour les tuiles 2015 : 

	# Calcul du pourcentage de points classifiÃ© en "x" code de classe pour l'annÃ©e 2015:
    
	resultats2015 = [] # Liste vide contenant les rÃ©ultats du calcule du pourcentage de points classifiÃ© selon "x" classecode

	tuiles2015 = [] # Liste vide contenant le nom de la tuile qui est calculÃ©

	def pourcentage2015(dossier): # Fonction qui calcule
    
   		for f in os.listdir(dossier):
            
        		if f.endswith('.las'): # S'assurer que seuls les fichier .las sont sÃ©lectionnÃ©s
                
            			chemin_fichier = os.path.join(dossier, f)
                
            			with lp.open(chemin_fichier) as g: # Ouvrir le 
                    
                		t2015 = g.read()
                   
                		num_points = len(t2015) # Nombre de points dans la tuile
                
                		if num_points > 0: # Filtre pour ne pas diviser par 0 mais scÃ©nario impossible ici.
                    
                    			num_points_classcode = len(t2015[t2015.classification == 1]) # Nombre de points classifiÃ© selon le code de classe choisi
                   
                    			pourcentage_points_classecode = (num_points_classcode/num_points) *100 # Calcule du pourcentage
                    
                		else:
                    			pourcentage_points_classecode = 0.0
                
                		numero_tuile = f[:8] # Chercher le nom de la tuile (les 9 premiers caractÃ¨res du fichier)
                   
                		resultats2015.append(pourcentage_points_classecode) # Ajouter le pourcentage Ã  la liste resultats2018
                    
                		tuiles2015.append(numero_tuile) # Ajouter le nom de la tuile Ã  la liste tuiles2018
                
    		df_resultats2015 = pd.DataFrame(
        	{'Tuile2015': tuiles2015,
         	'Pourcentage de points classifiÃ©s 2015 (Classe 1)': resultats2015
    		}) # Mettre le rÃ©sultat des deux listes dans un dataframe
                    
                    
                    
    		return df_resultats2015

	dossier = r"D:\UNIVERSITE\UQAM\Contrat\Comparaison_2015_2018\LiDAR_2015\LAS2015_classifiees_266-279"
	df_resultats_2015 =  pourcentage2015(dossier)


# 2Ã¨me Ã©chantillon de test.

## ğŸ› ï¸ Test du Code sur un Ã‰chantillon RÃ©duit  

Pour tester ce code, jâ€™ai effectuÃ© un test sur un **Ã©chantillon rÃ©duit** comprenant **5 tuiles** de 2015 et **5 tuiles** de 2018.  

### ğŸ¯ Objectif du Test  
Lâ€™objectif Ã©tait simplement de **vÃ©rifier le bon fonctionnement du code**, sans chercher Ã  comparer directement les valeurs entre 2015 et 2018.  

### âš ï¸ DiffÃ©rences dans lâ€™Ã©chantillon  
ğŸš¨ **Les tuiles sÃ©lectionnÃ©es ne sont pas les mÃªmes pour 2015 et 2018**, car je n'avais pas prÃ©vu de soustraire les rÃ©sultats entre les deux annÃ©es.  
ğŸ” Le test visait uniquement Ã  sâ€™assurer que les **rÃ©sultats Ã©taient cohÃ©rents** :  
- **Le calcul du pourcentage Ã©tait correct**.  
- **Chaque tuile Ã©tait bien associÃ©e Ã  son rÃ©sultat dans le DataFrame*


# 3Ã¨me Ã©chantillon de test

## ğŸ”„ Fusion des DataFrames pour l'Analyse des DiffÃ©rences  

Les codes pour le calcul des pourcentages Ã©tant **fonctionnels**, jâ€™ai ajoutÃ© une **section fusionnant les deux DataFrames** en un seul.  

### ğŸ¯ Objectif  
Lâ€™objectif est de **regrouper toutes les donnÃ©es** dans un **unique DataFrame** afin de faciliter lâ€™analyse des diffÃ©rences entre 2015 et 2018.  

### ğŸ”§ MÃ©thode  

**Fusion des DataFrames** avec la mÃ©thode **.merge**



	# Fusion des 2 DataFrame et soustraction des rÃ©sultats

	df_comparaison = df_resultats_2018.merge(df_resultats_2015[["Tuile2015", "Pourcentage de points classifiÃ©s 2015 (Classe 1)" ]], left_on="Tuile2018", right_on="Tuile2015", how="left")
	df_comparaison["DiffÃ©rence"] = df_comparaison["Pourcentage de points classifiÃ©s 2018 (Classe 1)"] - df_comparaison["Pourcentage de points classifiÃ©s 2015 (Classe 1)"]

	print(df_comparaison)
 

### ğŸ§ª Test de Fusion avec DonnÃ©es Non Concordantes  

Apres quoi j'ai rÃ©alisÃ© le premier test complet, sur un Ã©chantillon rÃ©duit : 


| Tuile      | 2015     | 2018     |
|------------|---------|---------|
| 295-5029   | âœ…       | âŒ       |
| 295-5030   | âœ…       | âœ…       |
| 295-5031   | âœ…       | âœ…       |
| 295-5032   | âœ…       | âœ…       |
| 295-5033   | âœ…       | âœ…       |
| 295-5034   | âŒ       | âœ…       |



Jâ€™ai **dÃ©libÃ©rÃ©ment choisi** des donnÃ©es **non parfaitement concordantes** entre **2015 et 2018** afin dâ€™observer le comportement du code lors de la fusion des deux DataFrames.  

### ğŸ¯ Objectif  
Tester la gestion des **valeurs manquantes** et vÃ©rifier si la fusion des DataFrames entraÃ®ne des erreurs ou un dÃ©calage des lignes.  

### âœ… RÃ©sultats  
- **RÃ©sultat positif** :  
  - Lorsque le code ne peut pas effectuer la soustraction entre 2018 et 2015 (car une tuile est absente dâ€™un des jeux de donnÃ©es), le **DataFrame insÃ¨re un "NaN"**.  
  - **Aucun dÃ©calage** observÃ© dans les lignes du DataFrame.  

ğŸ” **Conclusion** : Le code gÃ¨re correctement les donnÃ©es non concordantes et maintient lâ€™intÃ©gritÃ© des rÃ©sultats.  


# 4Ã¨me Ã©chantillon

## ğŸ“Š Test de Grande Ampleur sur le premier fichiers de tuiles (266-279)  

### ğŸš€ RÃ©sultats du Test  
- **SuccÃ¨s pour 2015** âœ…  
- **Ã‰chec pour 2018** âŒ : Un fichier semble Ãªtre corrompu.  

### ğŸ” DÃ©tection du Fichier Corrompu  
Pour identifier le fichier problÃ©matique, jâ€™ai exÃ©cutÃ© le code suivant :

	dossier = r"D:\UNIVERSITE\UQAM\Projet\DISQUE_5_DANS_8\LIDAR_2018\LAS_classifiees\266-279"

	for f in os.listdir(dossier):
    		if f.endswith('.las'):
        	chemin_fichier = os.path.join(dossier, f)
       		 with open(chemin_fichier, "rb") as fichier:
            		signature = fichier.read(4)
        	print(f"{f} â†’ Signature : {signature}")

Le script permet de relever la **signature des fichiers**.  
ğŸ”¹ Un fichier `.LAS` doit avoir une **signature = `b'LASF'`**.  
ğŸ”¹ Une tuile **(279-5031)** Ã©tait corrompue.  
ğŸš€ **Action** : Je lâ€™ai retirÃ©e du dossier avant de relancer le code.  

âœ… **SuccÃ¨s** : Le script fonctionne correctement aprÃ¨s cette correction.  

---

## ğŸ“‚ Export des RÃ©sultats et Visualisation  

Le code suivant permet de **transposer les rÃ©sultats dans un fichier CSV**.  
ğŸ“Œ **ProcÃ©dure** :  
1. Ouverture du fichier dans **Excel**.  
2. RÃ©enregistrement au format **CSV**.  
3. Import dans **ArcGIS**.
4. **Jointure avec le fichier shapefile des tuiles LiDAR 2015** pour visualiser les rÃ©sultats.  

![image](https://github.com/user-attachments/assets/9f175a29-fffb-4374-b055-a16a2489d0a3)

ğŸ” **Observation** :  
â¡ï¸ **Augmentation du pourcentage de points non classifiÃ©s** pour **les tuiles de lâ€™extrÃªme est de lâ€™Ã®le**.  

---

## ğŸ“… Semaine du 17 mars  

### ğŸ“Œ Analyse des donnÃ©es "non-classifiÃ©es" (2015 vs 2018)  

ğŸ”¹ ExÃ©cution du script pour **toutes les tuiles** classifiÃ©es en **"non-classifiÃ©es"** en 2015 et 2018.  
ğŸ”¹ Fusion des **5 CSV par annÃ©e (2015 et 2018)** dans **ArcGIS** (`Comparaison_LiDAR_Classe1`).  
ğŸ”¹ **Jointure** entre le fichier fusionnÃ© et la couche **shapefile des tuiles LiDAR**.  

### ğŸ“Š RÃ©sultats de l'analyse  

![image](https://github.com/user-attachments/assets/1ba3e2fd-4767-4def-af80-c4937dd12f0b)

ğŸ”¸ **LÃ©gende** :  
âœ”ï¸ **Vert foncÃ©** â†’ Forte diminution du pourcentage de points "non-classifiÃ©s" entre 2015 et 2018.  
âš ï¸ **Orange / Rouge** â†’ Augmentation de plus de **15% Ã  30%** du pourcentage de points "non-classifiÃ©s" entre 2018 et 2015.  

ğŸ“Œ **Tendance gÃ©nÃ©rale** :  
â¡ï¸ **60% des tuiles** ont un **taux plus Ã©levÃ© de points "non-classifiÃ©s" en 2018** qu'en 2015.  

---

### ğŸŒ¿ Analyse des donnÃ©es "VÃ©gÃ©tation haute" (2015 vs 2018)  

ğŸ”¹ **MÃªme script**, seule la classification change :  

	num_points_classcode = len(t2015[t2015.classification == 5])  # Nombre de points classifiÃ©s selon le code choisi


ğŸ“Œ **ProcÃ©dure identique** :  
1. Ouverture du fichier dans **Excel**.  
2. RÃ©enregistrement au format **CSV**.  
3. Import dans **ArcGIS**.
4. **Jointure avec le fichier shapefile des tuiles LiDAR 2015** pour visualiser les rÃ©sultats.

![image](https://github.com/user-attachments/assets/ca46a135-a92c-4225-b6b6-ea6b7f46a9bd)

ğŸ”**Observation Ã©tonnante** :
â¡ï¸ Pour une grande majoritÃ© de l'Ã®le, le nombre de points classifiÃ©s en "vÃ©gÃ©tation haute" a augmentÃ© dâ€™au moins 10% entre 2015 et 2018. Ce rÃ©sultat vient contredire ceux obtenus lors de notre premier Ã©chantillon test.

# ğŸ“Œ RÃ©sumÃ© des rÃ©sultats

- **60% des tuiles** ont un pourcentage plus Ã©levÃ© de points **"non-classifiÃ©s" en 2018** qu'en 2015.
- **9.7% des tuiles** montrent une augmentation du pourcentage de points classifiÃ©s en **"vÃ©gÃ©tation haute" en 2018** par rapport Ã  2015.


# Suite du travail

- Effectuer le code pour les points classifiÃ©s en **"VÃ©gÃ©tation-moyenne"** et **"vÃ©gÃ©tation-basse"**
- Trouver une mÃ©thode pour assigner une classification aux valeurs non-classifiÃ©es dans les tuiles ou leur poucentage dÃ©passe une valeur seuil **"x"**
